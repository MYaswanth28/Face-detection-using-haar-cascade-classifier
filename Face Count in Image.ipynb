{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing cv2 Package\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Image \n",
    "img = cv2.imread(r'C:\\YASWANTH M\\KARE-VII SEMESTER\\AM\\new_img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 249]\n",
      "  [255 255 249]\n",
      "  [254 254 248]\n",
      "  ...\n",
      "  [106 120 119]\n",
      "  [103 116 118]\n",
      "  [102 115 117]]\n",
      "\n",
      " [[247 245 237]\n",
      "  [253 252 242]\n",
      "  [255 255 247]\n",
      "  ...\n",
      "  [ 91 106 108]\n",
      "  [ 90 105 108]\n",
      "  [ 91 106 109]]\n",
      "\n",
      " [[253 252 238]\n",
      "  [254 254 238]\n",
      "  [253 252 238]\n",
      "  ...\n",
      "  [ 95 111 117]\n",
      "  [ 99 115 122]\n",
      "  [ 98 114 121]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[223 226 224]\n",
      "  [223 228 226]\n",
      "  [220 226 225]\n",
      "  ...\n",
      "  [236 232 237]\n",
      "  [252 249 251]\n",
      "  [242 239 241]]\n",
      "\n",
      " [[227 230 228]\n",
      "  [225 230 228]\n",
      "  [220 226 225]\n",
      "  ...\n",
      "  [230 227 229]\n",
      "  [255 254 255]\n",
      "  [248 246 246]]\n",
      "\n",
      " [[218 223 222]\n",
      "  [225 230 229]\n",
      "  [220 226 225]\n",
      "  ...\n",
      "  [222 220 220]\n",
      "  [254 252 252]\n",
      "  [252 250 249]]]\n"
     ]
    }
   ],
   "source": [
    "#Printing the Image \n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Image to Gray Scale \n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required haar-cascade xml classifier file\n",
    "haar_cascade = cv2.CascadeClassifier(r'C:\\YASWANTH M\\KARE-VII SEMESTER\\AM\\Haar\\Haar-Training\\Haar Training\\cascade2xml\\myfacedetector.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the face detection method on the grayscale image\n",
    "# Reduced the minNeighbors parameter to 8 to allow more detections\n",
    "faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of detected faces\n",
    "num_faces = len(faces_rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 249],\n",
       "        [255, 255, 249],\n",
       "        [254, 254, 248],\n",
       "        ...,\n",
       "        [106, 120, 119],\n",
       "        [103, 116, 118],\n",
       "        [102, 115, 117]],\n",
       "\n",
       "       [[247, 245, 237],\n",
       "        [253, 252, 242],\n",
       "        [255, 255, 247],\n",
       "        ...,\n",
       "        [ 91, 106, 108],\n",
       "        [ 90, 105, 108],\n",
       "        [ 91, 106, 109]],\n",
       "\n",
       "       [[253, 252, 238],\n",
       "        [254, 254, 238],\n",
       "        [253, 252, 238],\n",
       "        ...,\n",
       "        [ 95, 111, 117],\n",
       "        [ 99, 115, 122],\n",
       "        [ 98, 114, 121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[223, 226, 224],\n",
       "        [223, 228, 226],\n",
       "        [220, 226, 225],\n",
       "        ...,\n",
       "        [236, 232, 237],\n",
       "        [252, 249, 251],\n",
       "        [242, 239, 241]],\n",
       "\n",
       "       [[227, 230, 228],\n",
       "        [225, 230, 228],\n",
       "        [220, 226, 225],\n",
       "        ...,\n",
       "        [230, 227, 229],\n",
       "        [255, 254, 255],\n",
       "        [248, 246, 246]],\n",
       "\n",
       "       [[218, 223, 222],\n",
       "        [225, 230, 229],\n",
       "        [220, 226, 225],\n",
       "        ...,\n",
       "        [222, 220, 220],\n",
       "        [254, 252, 252],\n",
       "        [252, 250, 249]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw text on the image to display the count of faces\n",
    "text = f\"Number of faces: {num_faces}\"\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterating through rectangles of detected faces\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "cv2.imshow('Detected faces', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full Code \n",
    "# Importing OpenCV package\n",
    "import cv2\n",
    "\n",
    "# Reading the image\n",
    "img = cv2.imread(r'C:\\YASWANTH M\\KARE-VII SEMESTER\\AM\\new_img.jpg')\n",
    "\n",
    "# Converting image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Loading the required haar-cascade xml classifier file\n",
    "haar_cascade = cv2.CascadeClassifier(r'C:\\YASWANTH M\\KARE-VII SEMESTER\\AM\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Applying the face detection method on the grayscale image\n",
    "# Reduced the minNeighbors parameter to 1 to allow more detections\n",
    "faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=8)# Counting the number of detected faces\n",
    "num_faces = len(faces_rect)\n",
    "\n",
    "# Draw text on the image to display the count of faces\n",
    "text = f\"Number of faces: {num_faces}\"\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "# Iterating through rectangles of detected faces\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Detected faces', img)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
